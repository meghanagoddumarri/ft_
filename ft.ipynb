{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95842638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (91 kB)\n",
      "Collecting numpy\n",
      "  Downloading numpy-2.4.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting networkx\n",
      "  Downloading networkx-3.6.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.8.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (11 kB)\n",
      "Collecting scip\n",
      "  Downloading scip-0.1.12-py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/codespace/.local/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/codespace/.local/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Collecting scipy>=1.10.0 (from scikit-learn)\n",
      "  Downloading scipy-1.16.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (62 kB)\n",
      "Collecting joblib>=1.3.0 (from scikit-learn)\n",
      "  Downloading joblib-1.5.3-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting threadpoolctl>=3.2.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting Pillow (from scip)\n",
      "  Downloading pillow-12.0.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.8 kB)\n",
      "Collecting dask>=2022.01.1 (from dask[distributed]>=2022.01.1->scip)\n",
      "  Downloading dask-2025.12.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: click in /usr/local/python/3.12.1/lib/python3.12/site-packages (from scip) (8.3.1)\n",
      "Collecting scikit-image (from scip)\n",
      "  Downloading scikit_image-0.26.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (15 kB)\n",
      "Requirement already satisfied: pyyaml in /home/codespace/.local/lib/python3.12/site-packages (from scip) (6.0.3)\n",
      "Collecting graphviz (from scip)\n",
      "  Downloading graphviz-0.21-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting zarr (from scip)\n",
      "  Downloading zarr-3.1.5-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pyarrow (from scip)\n",
      "  Downloading pyarrow-22.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.2 kB)\n",
      "Collecting anndata (from scip)\n",
      "  Downloading anndata-0.12.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting numba (from scip)\n",
      "  Downloading numba-0.63.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.9 kB)\n",
      "Collecting aicsimageio (from scip)\n",
      "  Downloading aicsimageio-4.14.0-py2.py3-none-any.whl.metadata (20 kB)\n",
      "Collecting cloudpickle>=3.0.0 (from dask>=2022.01.1->dask[distributed]>=2022.01.1->scip)\n",
      "  Downloading cloudpickle-3.1.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting fsspec>=2021.09.0 (from dask>=2022.01.1->dask[distributed]>=2022.01.1->scip)\n",
      "  Downloading fsspec-2025.12.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/codespace/.local/lib/python3.12/site-packages (from dask>=2022.01.1->dask[distributed]>=2022.01.1->scip) (25.0)\n",
      "Collecting partd>=1.4.0 (from dask>=2022.01.1->dask[distributed]>=2022.01.1->scip)\n",
      "  Downloading partd-1.4.2-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting toolz>=0.12.0 (from dask>=2022.01.1->dask[distributed]>=2022.01.1->scip)\n",
      "  Downloading toolz-1.1.0-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting distributed<2025.12.1,>=2025.12.0 (from dask[distributed]>=2022.01.1->scip)\n",
      "  Downloading distributed-2025.12.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: jinja2>=2.10.3 in /home/codespace/.local/lib/python3.12/site-packages (from distributed<2025.12.1,>=2025.12.0->dask[distributed]>=2022.01.1->scip) (3.1.6)\n",
      "Collecting locket>=1.0.0 (from distributed<2025.12.1,>=2025.12.0->dask[distributed]>=2022.01.1->scip)\n",
      "  Downloading locket-1.0.0-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting msgpack>=1.0.2 (from distributed<2025.12.1,>=2025.12.0->dask[distributed]>=2022.01.1->scip)\n",
      "  Downloading msgpack-1.1.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (8.1 kB)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /home/codespace/.local/lib/python3.12/site-packages (from distributed<2025.12.1,>=2025.12.0->dask[distributed]>=2022.01.1->scip) (7.1.3)\n",
      "Collecting sortedcontainers>=2.0.5 (from distributed<2025.12.1,>=2025.12.0->dask[distributed]>=2022.01.1->scip)\n",
      "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting tblib!=3.2.0,!=3.2.1,>=1.6.0 (from distributed<2025.12.1,>=2025.12.0->dask[distributed]>=2022.01.1->scip)\n",
      "  Downloading tblib-3.2.2-py3-none-any.whl.metadata (27 kB)\n",
      "Requirement already satisfied: tornado>=6.2.0 in /home/codespace/.local/lib/python3.12/site-packages (from distributed<2025.12.1,>=2025.12.0->dask[distributed]>=2022.01.1->scip) (6.5.2)\n",
      "Requirement already satisfied: urllib3>=1.26.5 in /home/codespace/.local/lib/python3.12/site-packages (from distributed<2025.12.1,>=2025.12.0->dask[distributed]>=2022.01.1->scip) (2.5.0)\n",
      "Collecting zict>=3.0.0 (from distributed<2025.12.1,>=2025.12.0->dask[distributed]>=2022.01.1->scip)\n",
      "  Downloading zict-3.0.0-py2.py3-none-any.whl.metadata (899 bytes)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/codespace/.local/lib/python3.12/site-packages (from jinja2>=2.10.3->distributed<2025.12.1,>=2025.12.0->dask[distributed]>=2022.01.1->scip) (3.0.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/codespace/.local/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Collecting fsspec>=2021.09.0 (from dask>=2022.01.1->dask[distributed]>=2022.01.1->scip)\n",
      "  Downloading fsspec-2023.6.0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting imagecodecs>=2020.5.30 (from aicsimageio->scip)\n",
      "  Downloading imagecodecs-2025.11.11-cp311-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (20 kB)\n",
      "Collecting lxml<5,>=4.6 (from aicsimageio->scip)\n",
      "  Downloading lxml-4.9.4-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.7 kB)\n",
      "Collecting ome-types>=0.3.4 (from aicsimageio->scip)\n",
      "  Downloading ome_types-0.6.3-py3-none-any.whl.metadata (9.8 kB)\n",
      "Collecting ome-zarr>=0.6.1 (from aicsimageio->scip)\n",
      "  Downloading ome_zarr-0.12.2-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting wrapt>=1.12 (from aicsimageio->scip)\n",
      "  Downloading wrapt-2.0.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (9.0 kB)\n",
      "Collecting resource-backed-dask-array>=0.1.0 (from aicsimageio->scip)\n",
      "  Downloading resource_backed_dask_array-0.1.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting tifffile<2023.3.15,>=2021.8.30 (from aicsimageio->scip)\n",
      "  Downloading tifffile-2023.2.28-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting xarray>=0.16.1 (from aicsimageio->scip)\n",
      "  Downloading xarray-2025.12.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting xmlschema (from aicsimageio->scip)\n",
      "  Downloading xmlschema-4.2.0-py3-none-any.whl.metadata (8.0 kB)\n",
      "Collecting zarr (from scip)\n",
      "  Downloading zarr-2.15.0-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting asciitree (from zarr->scip)\n",
      "  Downloading asciitree-0.3.3.tar.gz (4.0 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting fasteners (from zarr->scip)\n",
      "  Downloading fasteners-0.20-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting numcodecs>=0.10.0 (from zarr->scip)\n",
      "  Downloading numcodecs-0.16.5-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: typing_extensions in /home/codespace/.local/lib/python3.12/site-packages (from numcodecs>=0.10.0->zarr->scip) (4.15.0)\n",
      "Collecting pydantic-extra-types>=2.0.0 (from ome-types>=0.3.4->aicsimageio->scip)\n",
      "  Downloading pydantic_extra_types-2.10.6-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting pydantic>=2.4.0 (from ome-types>=0.3.4->aicsimageio->scip)\n",
      "  Downloading pydantic-2.12.5-py3-none-any.whl.metadata (90 kB)\n",
      "Collecting xsdata>=24.4 (from ome-types>=0.3.4->aicsimageio->scip)\n",
      "  Downloading xsdata-25.7-py3-none-any.whl.metadata (5.5 kB)\n",
      "INFO: pip is looking at multiple versions of ome-zarr to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting ome-zarr>=0.6.1 (from aicsimageio->scip)\n",
      "  Downloading ome_zarr-0.12.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Downloading ome_zarr-0.12.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Downloading ome_zarr-0.11.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting aiohttp<4 (from ome-zarr>=0.6.1->aicsimageio->scip)\n",
      "  Downloading aiohttp-3.13.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (8.1 kB)\n",
      "Requirement already satisfied: requests in /home/codespace/.local/lib/python3.12/site-packages (from ome-zarr>=0.6.1->aicsimageio->scip) (2.32.5)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp<4->ome-zarr>=0.6.1->aicsimageio->scip)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp<4->ome-zarr>=0.6.1->aicsimageio->scip)\n",
      "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/codespace/.local/lib/python3.12/site-packages (from aiohttp<4->ome-zarr>=0.6.1->aicsimageio->scip) (25.4.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4->ome-zarr>=0.6.1->aicsimageio->scip)\n",
      "  Downloading frozenlist-1.8.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (20 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4->ome-zarr>=0.6.1->aicsimageio->scip)\n",
      "  Downloading multidict-6.7.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4->ome-zarr>=0.6.1->aicsimageio->scip)\n",
      "  Downloading propcache-0.4.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4->ome-zarr>=0.6.1->aicsimageio->scip)\n",
      "  Downloading yarl-1.22.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (75 kB)\n",
      "Requirement already satisfied: idna>=2.0 in /home/codespace/.local/lib/python3.12/site-packages (from yarl<2.0,>=1.17.0->aiohttp<4->ome-zarr>=0.6.1->aicsimageio->scip) (3.11)\n",
      "Collecting s3fs (from fsspec[s3]!=2021.07.0,!=2023.9.0,>=0.8->ome-zarr>=0.6.1->aicsimageio->scip)\n",
      "  Downloading s3fs-2025.12.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic>=2.4.0->ome-types>=0.3.4->aicsimageio->scip)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.41.5 (from pydantic>=2.4.0->ome-types>=0.3.4->aicsimageio->scip)\n",
      "  Downloading pydantic_core-2.41.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspection>=0.4.2 (from pydantic>=2.4.0->ome-types>=0.3.4->aicsimageio->scip)\n",
      "  Downloading typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting array-api-compat>=1.7.1 (from anndata->scip)\n",
      "  Downloading array_api_compat-1.12.0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting h5py>=3.8 (from anndata->scip)\n",
      "  Downloading h5py-3.15.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting legacy-api-wrap (from anndata->scip)\n",
      "  Downloading legacy_api_wrap-1.5-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting natsort (from anndata->scip)\n",
      "  Downloading natsort-8.4.0-py3-none-any.whl.metadata (21 kB)\n",
      "INFO: pip is looking at multiple versions of anndata to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting anndata (from scip)\n",
      "  Downloading anndata-0.12.6-py3-none-any.whl.metadata (10.0 kB)\n",
      "  Downloading anndata-0.12.5-py3-none-any.whl.metadata (9.9 kB)\n",
      "  Downloading anndata-0.12.4-py3-none-any.whl.metadata (9.9 kB)\n",
      "  Downloading anndata-0.12.3-py3-none-any.whl.metadata (9.9 kB)\n",
      "  Downloading anndata-0.12.2-py3-none-any.whl.metadata (9.6 kB)\n",
      "  Downloading anndata-0.12.1-py3-none-any.whl.metadata (9.6 kB)\n",
      "  Downloading anndata-0.12.0-py3-none-any.whl.metadata (9.6 kB)\n",
      "INFO: pip is still looking at multiple versions of anndata to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading anndata-0.11.4-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting llvmlite<0.47,>=0.46.0dev0 (from numba->scip)\n",
      "  Downloading llvmlite-0.46.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (5.0 kB)\n",
      "Collecting numpy\n",
      "  Downloading numpy-2.3.5-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests->ome-zarr>=0.6.1->aicsimageio->scip) (3.4.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.12/site-packages (from requests->ome-zarr>=0.6.1->aicsimageio->scip) (2025.11.12)\n",
      "Collecting aiobotocore<3.0.0,>=2.5.4 (from s3fs->fsspec[s3]!=2021.07.0,!=2023.9.0,>=0.8->ome-zarr>=0.6.1->aicsimageio->scip)\n",
      "  Downloading aiobotocore-2.26.0-py3-none-any.whl.metadata (25 kB)\n",
      "INFO: pip is looking at multiple versions of s3fs to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting s3fs (from fsspec[s3]!=2021.07.0,!=2023.9.0,>=0.8->ome-zarr>=0.6.1->aicsimageio->scip)\n",
      "  Downloading s3fs-2025.10.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "  Downloading s3fs-2025.9.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "  Downloading s3fs-2025.7.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "  Downloading s3fs-2025.5.1-py3-none-any.whl.metadata (1.9 kB)\n",
      "  Downloading s3fs-2025.5.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "  Downloading s3fs-2025.3.2-py3-none-any.whl.metadata (1.9 kB)\n",
      "  Downloading s3fs-2025.3.1-py3-none-any.whl.metadata (1.9 kB)\n",
      "INFO: pip is still looking at multiple versions of s3fs to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading s3fs-2025.3.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "  Downloading s3fs-2025.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "  Downloading s3fs-2024.12.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "  Downloading s3fs-2024.10.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "  Downloading s3fs-2024.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Downloading s3fs-2024.6.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "  Downloading s3fs-2024.6.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "  Downloading s3fs-2024.5.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "  Downloading s3fs-2024.3.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "  Downloading s3fs-2024.3.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "  Downloading s3fs-2024.2.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "  Downloading s3fs-2023.12.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "  Downloading s3fs-2023.12.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "  Downloading s3fs-2023.10.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting aiobotocore~=2.7.0 (from s3fs->fsspec[s3]!=2021.07.0,!=2023.9.0,>=0.8->ome-zarr>=0.6.1->aicsimageio->scip)\n",
      "  Downloading aiobotocore-2.7.0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting s3fs (from fsspec[s3]!=2021.07.0,!=2023.9.0,>=0.8->ome-zarr>=0.6.1->aicsimageio->scip)\n",
      "  Downloading s3fs-2023.9.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting aiobotocore~=2.5.4 (from s3fs->fsspec[s3]!=2021.07.0,!=2023.9.0,>=0.8->ome-zarr>=0.6.1->aicsimageio->scip)\n",
      "  Downloading aiobotocore-2.5.4-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting s3fs (from fsspec[s3]!=2021.07.0,!=2023.9.0,>=0.8->ome-zarr>=0.6.1->aicsimageio->scip)\n",
      "  Downloading s3fs-2023.9.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "  Downloading s3fs-2023.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "  Downloading s3fs-2023.6.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting botocore<1.31.18,>=1.31.17 (from aiobotocore~=2.5.4->s3fs->fsspec[s3]!=2021.07.0,!=2023.9.0,>=0.8->ome-zarr>=0.6.1->aicsimageio->scip)\n",
      "  Downloading botocore-1.31.17-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting wrapt>=1.12 (from aicsimageio->scip)\n",
      "  Downloading wrapt-1.17.3-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (6.4 kB)\n",
      "Collecting aioitertools<1.0.0,>=0.5.1 (from aiobotocore~=2.5.4->s3fs->fsspec[s3]!=2021.07.0,!=2023.9.0,>=0.8->ome-zarr>=0.6.1->aicsimageio->scip)\n",
      "  Downloading aioitertools-0.13.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting jmespath<2.0.0,>=0.7.1 (from botocore<1.31.18,>=1.31.17->aiobotocore~=2.5.4->s3fs->fsspec[s3]!=2021.07.0,!=2023.9.0,>=0.8->ome-zarr>=0.6.1->aicsimageio->scip)\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting urllib3>=1.26.5 (from distributed<2025.12.1,>=2025.12.0->dask[distributed]>=2022.01.1->scip)\n",
      "  Downloading urllib3-1.26.20-py2.py3-none-any.whl.metadata (50 kB)\n",
      "Collecting imageio!=2.35.0,>=2.33 (from scikit-image->scip)\n",
      "  Downloading imageio-2.37.2-py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting lazy-loader>=0.4 (from scikit-image->scip)\n",
      "  Downloading lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting elementpath<6.0.0,>=5.0.1 (from xmlschema->aicsimageio->scip)\n",
      "  Downloading elementpath-5.0.4-py3-none-any.whl.metadata (7.0 kB)\n",
      "Downloading pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm0:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading networkx-3.6.1-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.8.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (8.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading scip-0.1.12-py3-none-any.whl (61 kB)\n",
      "Downloading dask-2025.12.0-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cloudpickle-3.1.2-py3-none-any.whl (22 kB)\n",
      "Downloading distributed-2025.12.0-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.5.3-py3-none-any.whl (309 kB)\n",
      "Downloading locket-1.0.0-py2.py3-none-any.whl (4.4 kB)\n",
      "Downloading msgpack-1.1.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (427 kB)\n",
      "Downloading partd-1.4.2-py3-none-any.whl (18 kB)\n",
      "Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading scipy-1.16.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (35.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.7/35.7 MB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Downloading tblib-3.2.2-py3-none-any.whl (12 kB)\n",
      "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Downloading toolz-1.1.0-py3-none-any.whl (58 kB)\n",
      "Downloading zict-3.0.0-py2.py3-none-any.whl (43 kB)\n",
      "Downloading aicsimageio-4.14.0-py2.py3-none-any.whl (138 kB)\n",
      "Downloading fsspec-2023.6.0-py3-none-any.whl (163 kB)\n",
      "Downloading lxml-4.9.4-cp312-cp312-manylinux_2_28_x86_64.whl (8.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tifffile-2023.2.28-py3-none-any.whl (216 kB)\n",
      "Downloading zarr-2.15.0-py3-none-any.whl (206 kB)\n",
      "Downloading imagecodecs-2025.11.11-cp311-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (23.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.2/23.2 MB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading numcodecs-0.16.5-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (9.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.2/9.2 MB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading ome_types-0.6.3-py3-none-any.whl (245 kB)\n",
      "Downloading ome_zarr-0.11.1-py3-none-any.whl (40 kB)\n",
      "Downloading aiohttp-3.13.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multidict-6.7.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (256 kB)\n",
      "Downloading yarl-1.22.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (377 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Downloading frozenlist-1.8.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (242 kB)\n",
      "Downloading propcache-0.4.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (221 kB)\n",
      "Downloading pydantic-2.12.5-py3-none-any.whl (463 kB)\n",
      "Downloading pydantic_core-2.41.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading pydantic_extra_types-2.10.6-py3-none-any.whl (40 kB)\n",
      "Downloading resource_backed_dask_array-0.1.0-py2.py3-none-any.whl (8.0 kB)\n",
      "Downloading typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Downloading xarray-2025.12.0-py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading xsdata-25.7-py3-none-any.whl (234 kB)\n",
      "Downloading anndata-0.11.4-py3-none-any.whl (144 kB)\n",
      "Downloading array_api_compat-1.12.0-py3-none-any.whl (58 kB)\n",
      "Downloading h5py-3.15.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (5.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fasteners-0.20-py3-none-any.whl (18 kB)\n",
      "Downloading graphviz-0.21-py3-none-any.whl (47 kB)\n",
      "Downloading natsort-8.4.0-py3-none-any.whl (38 kB)\n",
      "Downloading numba-0.63.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.3.5-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading llvmlite-0.46.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pillow-12.0.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (7.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-22.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (47.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading s3fs-2023.6.0-py3-none-any.whl (28 kB)\n",
      "Downloading aiobotocore-2.5.4-py3-none-any.whl (73 kB)\n",
      "Downloading aioitertools-0.13.0-py3-none-any.whl (24 kB)\n",
      "Downloading botocore-1.31.17-py3-none-any.whl (11.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.1/11.1 MB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Downloading urllib3-1.26.20-py2.py3-none-any.whl (144 kB)\n",
      "Downloading wrapt-1.17.3-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (88 kB)\n",
      "Downloading scikit_image-0.26.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (13.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.6/13.6 MB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading imageio-2.37.2-py3-none-any.whl (317 kB)\n",
      "Downloading lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Downloading xmlschema-4.2.0-py3-none-any.whl (467 kB)\n",
      "Downloading elementpath-5.0.4-py3-none-any.whl (245 kB)\n",
      "Building wheels for collected packages: asciitree\n",
      "  Building wheel for asciitree (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for asciitree: filename=asciitree-0.3.3-py3-none-any.whl size=5096 sha256=0a85315ad650bf9e08134ef0b58aeefe76f28dacb03d2f96d7a386308796a2d4\n",
      "  Stored in directory: /home/codespace/.cache/pip/wheels/a5/d7/98/f56ae733748cd0fa577172bda0e73e0b1f1793c98e09b9e458\n",
      "Successfully built asciitree\n",
      "Installing collected packages: sortedcontainers, pytz, asciitree, zict, xsdata, wrapt, urllib3, typing-inspection, toolz, threadpoolctl, tblib, pydantic-core, pyarrow, propcache, Pillow, numpy, networkx, natsort, multidict, msgpack, lxml, locket, llvmlite, lazy-loader, joblib, jmespath, graphviz, fsspec, frozenlist, fasteners, elementpath, cloudpickle, array-api-compat, annotated-types, aioitertools, aiohappyeyeballs, yarl, xmlschema, tifffile, scipy, pydantic, partd, pandas, numcodecs, numba, imageio, imagecodecs, h5py, botocore, aiosignal, zarr, xarray, scikit-learn, scikit-image, pydantic-extra-types, dask, anndata, aiohttp, ome-types, distributed, aiobotocore, s3fs, resource-backed-dask-array, ome-zarr, aicsimageio, scip\n",
      "\u001b[2K   \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/66\u001b[0m [xsdata]\u001b[33m  WARNING: The script xsdata is installed in '/usr/local/python/3.12.1/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[2K  Attempting uninstall: urllib3━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/66\u001b[0m [wrapt]\n",
      "\u001b[2K    Found existing installation: urllib3 2.5.0━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/66\u001b[0m [wrapt]\n",
      "\u001b[2K    Uninstalling urllib3-2.5.0:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/66\u001b[0m [wrapt]\n",
      "\u001b[2K      Successfully uninstalled urllib3-2.5.0━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/66\u001b[0m [wrapt]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15/66\u001b[0m [numpy]]]\u001b[33m  WARNING: The scripts f2py and numpy-config are installed in '/usr/local/python/3.12.1/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16/66\u001b[0m [networkx]\u001b[33m  WARNING: The script natsort is installed in '/usr/local/python/3.12.1/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37/66\u001b[0m [xmlschema]ls]\u001b[33m  WARNING: The scripts xmlschema-json2xml, xmlschema-validate and xmlschema-xml2json are installed in '/usr/local/python/3.12.1/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38/66\u001b[0m [tifffile]\u001b[33m  WARNING: The scripts lsm2bin, tiff2fsspec, tiffcomment and tifffile are installed in '/usr/local/python/3.12.1/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m45/66\u001b[0m [imageio]\u001b[33m  WARNING: The scripts imageio_download_bin and imageio_remove_bin are installed in '/usr/local/python/3.12.1/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m46/66\u001b[0m [imagecodecs]\u001b[33m  WARNING: The script imagecodecs is installed in '/usr/local/python/3.12.1/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m55/66\u001b[0m [dask]tic-extra-types]\u001b[33m  WARNING: The script dask is installed in '/usr/local/python/3.12.1/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m59/66\u001b[0m [distributed]\u001b[33m  WARNING: The scripts dask-scheduler, dask-ssh and dask-worker are installed in '/usr/local/python/3.12.1/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m63/66\u001b[0m [ome-zarr]\u001b[33m  WARNING: The script ome_zarr is installed in '/usr/local/python/3.12.1/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script scip is installed in '/usr/local/python/3.12.1/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66/66\u001b[0m [scip]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "types-requests 2.32.4.20250913 requires urllib3>=2, but you have urllib3 1.26.20 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed Pillow-12.0.0 aicsimageio-4.14.0 aiobotocore-2.5.4 aiohappyeyeballs-2.6.1 aiohttp-3.13.2 aioitertools-0.13.0 aiosignal-1.4.0 anndata-0.11.4 annotated-types-0.7.0 array-api-compat-1.12.0 asciitree-0.3.3 botocore-1.31.17 cloudpickle-3.1.2 dask-2025.12.0 distributed-2025.12.0 elementpath-5.0.4 fasteners-0.20 frozenlist-1.8.0 fsspec-2023.6.0 graphviz-0.21 h5py-3.15.1 imagecodecs-2025.11.11 imageio-2.37.2 jmespath-1.0.1 joblib-1.5.3 lazy-loader-0.4 llvmlite-0.46.0 locket-1.0.0 lxml-4.9.4 msgpack-1.1.2 multidict-6.7.0 natsort-8.4.0 networkx-3.6.1 numba-0.63.1 numcodecs-0.16.5 numpy-2.3.5 ome-types-0.6.3 ome-zarr-0.11.1 pandas-2.3.3 partd-1.4.2 propcache-0.4.1 pyarrow-22.0.0 pydantic-2.12.5 pydantic-core-2.41.5 pydantic-extra-types-2.10.6 pytz-2025.2 resource-backed-dask-array-0.1.0 s3fs-2023.6.0 scikit-image-0.26.0 scikit-learn-1.8.0 scip-0.1.12 scipy-1.16.3 sortedcontainers-2.4.0 tblib-3.2.2 threadpoolctl-3.6.0 tifffile-2023.2.28 toolz-1.1.0 typing-inspection-0.4.2 urllib3-1.26.20 wrapt-1.17.3 xarray-2025.12.0 xmlschema-4.2.0 xsdata-25.7 yarl-1.22.0 zarr-2.15.0 zict-3.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas numpy networkx scikit-learn scip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1d31171",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from scipy.stats import ttest_rel, wilcoxon, f_oneway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17b1828a",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRUST_PATH = \"filmtrust_data/trust.txt\" \n",
    "OUTPUT_DIR = \"outputs_filmtrust\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "W_VALUES = [0.6, 0.7, 0.8, 0.9]\n",
    "EPS = 1e-15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecde195d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Directory: /workspaces/ft_\n",
      "Files in directory: ['outputs_filmtrust', '.git', 'ft.ipynb', '\\xa0filmtrust_data', 'README.md', 'film-trust.zip']\n",
      "Path exists? False\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 1. Print current working directory\n",
    "print(\"Current Directory:\", os.getcwd())\n",
    "\n",
    "# 2. List files in the current directory to see if 'filmtrust_data' is there\n",
    "print(\"Files in directory:\", os.listdir('.'))\n",
    "\n",
    "# 3. Check if the specific path exists\n",
    "print(\"Path exists?\", os.path.exists('filmtrust_data/trust.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55ed5382",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.rename('\\xa0filmtrust_data', 'filmtrust_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ecfe36ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "with zipfile.ZipFile('film-trust.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe4d47c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path exists now? True\n"
     ]
    }
   ],
   "source": [
    "TRUST_PATH = 'filmtrust_data/trust.txt'\n",
    "import os\n",
    "print(\"Path exists now?\", os.path.exists(TRUST_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e12d95ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Loaded FilmTrust | edges: 1853\n",
      "\n",
      "--- Data Preview ---\n",
      "   u     v  label\n",
      "0  2   966      1\n",
      "1  2   104      1\n",
      "2  5  1509      1\n",
      "3  6  1192      1\n",
      "4  7  1510      1\n",
      "\n",
      "Label Distribution (0 = Distrust, 1 = Trust):\n",
      "label\n",
      "1    1853\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:21: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:21: SyntaxWarning: invalid escape sequence '\\s'\n",
      "/tmp/ipykernel_6869/3082880394.py:21: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  df = pd.read_csv(path, sep='\\s+', header=None, names=[\"u\", \"v\", \"label\"])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# 1. FIX: Rename the folder to remove the hidden non-breaking space if it exists\n",
    "try:\n",
    "    if os.path.exists('\\xa0filmtrust_data'):\n",
    "        os.rename('\\xa0filmtrust_data', 'filmtrust_data')\n",
    "        print(\"[FIX] Renamed folder to remove hidden characters.\")\n",
    "except Exception as e:\n",
    "    pass\n",
    "\n",
    "# 2. Define the Path\n",
    "TRUST_PATH = 'filmtrust_data/trust.txt'\n",
    "\n",
    "def load_filmtrust(path):\n",
    "    \"\"\"\n",
    "    Loads the FilmTrust dataset.\n",
    "    Format: [TrusterID] [TrusteeID] [Value]\n",
    "    \"\"\"\n",
    "    # Using sep='\\s+' handles spaces or tabs automatically\n",
    "    df = pd.read_csv(path, sep='\\s+', header=None, names=[\"u\", \"v\", \"label\"])\n",
    "    \n",
    "    # Standardizing labels to binary: 1 if trust >= 1, else 0\n",
    "    df['label'] = (df['label'] >= 1).astype(int)\n",
    "    return df\n",
    "\n",
    "# 3. Execution\n",
    "if os.path.exists(TRUST_PATH):\n",
    "    df = load_filmtrust(TRUST_PATH)\n",
    "    y = df.label.values\n",
    "    \n",
    "    print(f\"[OK] Loaded FilmTrust | edges: {len(df)}\")\n",
    "    print(\"\\n--- Data Preview ---\")\n",
    "    print(df.head())\n",
    "    print(\"\\nLabel Distribution (0 = Distrust, 1 = Trust):\")\n",
    "    print(df['label'].value_counts())\n",
    "else:\n",
    "    print(f\"[ERROR] File not found at: {TRUST_PATH}\")\n",
    "    print(\"Check if the folder 'filmtrust_data' exists in your current directory.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "495e9114",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.DiGraph()\n",
    "for _, r in df.iterrows():\n",
    "    G.add_edge(r.u, r.v)\n",
    "UG = G.to_undirected()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d60e994",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for _, r in df.iterrows():\n",
    "    # Connectivity features\n",
    "    cn = len(list(nx.common_neighbors(UG, r.u, r.v))) if UG.has_node(r.u) and UG.has_node(r.v) else 0\n",
    "    \n",
    "    try:\n",
    "        jaccard = next(nx.jaccard_coefficient(UG, [(r.u, r.v)]))[2]\n",
    "        adamic = next(nx.adamic_adar_index(UG, [(r.u, r.v)]))[2]\n",
    "    except (nx.NetworkXError, StopIteration):\n",
    "        jaccard, adamic = 0, 0\n",
    "\n",
    "    rows.append({\n",
    "        \"u\": r.u, \"v\": r.v, \"label\": r.label,\n",
    "        \"u_in\": G.in_degree(r.u), \"u_out\": G.out_degree(r.u),\n",
    "        \"v_in\": G.in_degree(r.v), \"v_out\": G.out_degree(r.v),\n",
    "        \"cn\": cn, \"jaccard\": jaccard, \"adamic\": adamic,\n",
    "        \"pa\": G.degree(r.u) * G.degree(r.v)\n",
    "    })\n",
    "\n",
    "feature_df = pd.DataFrame(rows).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a977fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_cols = [\"u_in\", \"u_out\", \"v_in\", \"v_out\"]\n",
    "link_cols = [\"jaccard\", \"adamic\", \"pa\", \"cn\"]\n",
    "\n",
    "# Scaling\n",
    "for c in node_cols:\n",
    "    feature_df[c] = np.log1p(feature_df[c])\n",
    "feature_df[node_cols] = StandardScaler().fit_transform(feature_df[node_cols])\n",
    "\n",
    "feature_df[\"pa\"] = np.log1p(feature_df[\"pa\"])\n",
    "feature_df[link_cols] = MinMaxScaler().fit_transform(feature_df[link_cols])\n",
    "\n",
    "X = feature_df[node_cols + link_cols]\n",
    "\n",
    "# Reliability logic\n",
    "if len(np.unique(y)) > 1:\n",
    "    auc_scores = {c: roc_auc_score(y, X[c]) for c in X.columns}\n",
    "    mi_vals = mutual_info_classif(X, y, random_state=0)\n",
    "else:\n",
    "    # If FilmTrust only has positive trust, we use default weights\n",
    "    auc_scores = {c: 1.0 for c in X.columns}\n",
    "    mi_vals = np.ones(len(X.columns))\n",
    "\n",
    "mi_norm = dict(zip(X.columns, MinMaxScaler().fit_transform(mi_vals.reshape(-1,1)).flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a960176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PIPELINE COMPLETED ===\n"
     ]
    }
   ],
   "source": [
    "def sigmoid(x): return 1 / (1 + np.exp(-x))\n",
    "\n",
    "metrics = []\n",
    "for w in W_VALUES:\n",
    "    comp = {f: w * auc_scores[f] + (1 - w) * mi_norm[f] for f in X.columns}\n",
    "    alpha = {k: v / (sum(comp[f] for f in node_cols) + EPS) for k, v in comp.items() if k in node_cols}\n",
    "    beta  = {k: v / (sum(comp[f] for f in link_cols) + EPS) for k, v in comp.items() if k in link_cols}\n",
    "\n",
    "    z = (X[node_cols].values @ np.array(list(alpha.values())) +\n",
    "         X[link_cols].values @ np.array(list(beta.values())))\n",
    "\n",
    "    probs = sigmoid(z)\n",
    "    loss = -(y * np.log(probs + EPS) + (1 - y) * np.log(1 - probs + EPS))\n",
    "\n",
    "    metrics.append([w, \n",
    "                    roc_auc_score(y, probs) if len(np.unique(y)) > 1 else 0,\n",
    "                    average_precision_score(y, probs) if len(np.unique(y)) > 1 else 0,\n",
    "                    loss.mean()])\n",
    "\n",
    "# Save\n",
    "pd.DataFrame(metrics, columns=[\"w\",\"AUC\",\"AP\",\"LogLoss\"]).to_csv(f\"{OUTPUT_DIR}/ft_results.csv\", index=False)\n",
    "print(f\"=== PIPELINE COMPLETED ===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "07dc8772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[...] Generating negative samples for balanced evaluation\n",
      "[OK] Data Loaded | Positives: 1853 | Negatives: 1853\n",
      "[...] Extracting features for all pairs\n",
      "[OK] w=0.6 processed\n",
      "[OK] w=0.7 processed\n",
      "[OK] w=0.8 processed\n",
      "[OK] w=0.9 processed\n",
      "\n",
      "=== FILMTRUST PIPELINE COMPLETED ===\n",
      "Results saved to outputs_filmtrust/ft_final_metrics.csv\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# FilmTrust Trust Prediction Pipeline (With Negative Sampling)\n",
    "# ============================================================\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from scipy.stats import ttest_rel, wilcoxon, f_oneway\n",
    "\n",
    "# ============================================================\n",
    "# CONFIG\n",
    "# ============================================================\n",
    "TRUST_PATH = \"filmtrust_data/trust.txt\"  # Path from your unzip step\n",
    "OUTPUT_DIR = \"outputs_filmtrust\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "W_VALUES = [0.6, 0.7, 0.8, 0.9]\n",
    "EPS = 1e-15\n",
    "\n",
    "# ============================================================\n",
    "# 1. LOAD DATA + NEGATIVE SAMPLING (Fixes AUC=0)\n",
    "# ============================================================\n",
    "def load_filmtrust_with_negatives(path):\n",
    "    # Load actual trust links (Positive Class)\n",
    "    # FilmTrust is space-separated: Truster Trustee Value\n",
    "    df_pos = pd.read_csv(path, sep=' ', header=None, names=[\"u\", \"v\", \"label\"])\n",
    "    df_pos['label'] = 1  # All existing links represent trust\n",
    "    \n",
    "    # Identify all unique nodes in the network\n",
    "    all_nodes = list(set(df_pos['u']) | set(df_pos['v']))\n",
    "    existing_edges = set(zip(df_pos['u'], df_pos['v']))\n",
    "    \n",
    "    # Generate Negative Samples (Edges that do NOT exist)\n",
    "    neg_rows = []\n",
    "    print(\"[...] Generating negative samples for balanced evaluation\")\n",
    "    while len(neg_rows) < len(df_pos):\n",
    "        u, v = random.sample(all_nodes, 2)\n",
    "        if (u, v) not in existing_edges:\n",
    "            neg_rows.append({\"u\": u, \"v\": v, \"label\": 0})\n",
    "            existing_edges.add((u, v))\n",
    "            \n",
    "    df_neg = pd.DataFrame(neg_rows)\n",
    "    # Combine and shuffle\n",
    "    return pd.concat([df_pos, df_neg]).sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "df = load_filmtrust_with_negatives(TRUST_PATH)\n",
    "y = df.label.values\n",
    "print(f\"[OK] Data Loaded | Positives: {sum(y)} | Negatives: {len(y)-sum(y)}\")\n",
    "\n",
    "# ============================================================\n",
    "# 2. BUILD GRAPH\n",
    "# ============================================================\n",
    "G = nx.DiGraph()\n",
    "# Only build the graph using Positive edges for feature calculation\n",
    "pos_edges = df[df.label == 1]\n",
    "for _, r in pos_edges.iterrows():\n",
    "    G.add_edge(r.u, r.v)\n",
    "\n",
    "UG = G.to_undirected()\n",
    "# ============================================================\n",
    "# 3. FEATURE EXTRACTION\n",
    "# ============================================================\n",
    "rows = []\n",
    "print(\"[...] Extracting features for all pairs\")\n",
    "for _, r in df.iterrows():\n",
    "    # Link features with safety checks for node existence\n",
    "    cn = len(list(nx.common_neighbors(UG, r.u, r.v))) if UG.has_node(r.u) and UG.has_node(r.v) else 0\n",
    "    \n",
    "    try:\n",
    "        jaccard = next(nx.jaccard_coefficient(UG, [(r.u, r.v)]))[2]\n",
    "        adamic = next(nx.adamic_adar_index(UG, [(r.u, r.v)]))[2]\n",
    "    except:\n",
    "        jaccard, adamic = 0, 0\n",
    "\n",
    "    rows.append({\n",
    "        \"u\": r.u, \"v\": r.v, \"label\": r.label,\n",
    "        \"u_in\":  G.in_degree(r.u) if G.has_node(r.u) else 0,\n",
    "        \"u_out\": G.out_degree(r.u) if G.has_node(r.u) else 0,\n",
    "        \"v_in\":  G.in_degree(r.v) if G.has_node(r.v) else 0,\n",
    "        \"v_out\": G.out_degree(r.v) if G.has_node(r.v) else 0,\n",
    "        \"cn\":    cn,\n",
    "        \"jaccard\": jaccard,\n",
    "        \"adamic\":  adamic,\n",
    "        \"pa\":    (G.degree(r.u) if G.has_node(r.u) else 0) * (G.degree(r.v) if G.has_node(r.v) else 0)\n",
    "    })\n",
    "feature_df = pd.DataFrame(rows).fillna(0)\n",
    "\n",
    "# ============================================================\n",
    "# 4. NORMALIZATION\n",
    "# ============================================================\n",
    "node_cols = [\"u_in\", \"u_out\", \"v_in\", \"v_out\"]\n",
    "link_cols = [\"jaccard\", \"adamic\", \"pa\", \"cn\"]\n",
    "\n",
    "for c in node_cols:\n",
    "    feature_df[c] = np.log1p(feature_df[c])\n",
    "feature_df[node_cols] = StandardScaler().fit_transform(feature_df[node_cols])\n",
    "\n",
    "feature_df[\"pa\"] = np.log1p(feature_df[\"pa\"])\n",
    "feature_df[link_cols] = MinMaxScaler().fit_transform(feature_df[link_cols])\n",
    "\n",
    "X = feature_df[node_cols + link_cols]\n",
    "\n",
    "# ============================================================\n",
    "# 5. FEATURE RELIABILITY (AUC + MI)\n",
    "# ============================================================\n",
    "auc_scores = {c: roc_auc_score(y, X[c]) for c in X.columns}\n",
    "mi_vals = mutual_info_classif(X, y, random_state=0)\n",
    "mi_norm = dict(zip(X.columns, MinMaxScaler().fit_transform(mi_vals.reshape(-1,1)).flatten()))\n",
    "\n",
    "# ============================================================\n",
    "# 6. TRUST MODEL + METRICS\n",
    "# ============================================================\n",
    "# ============================================================\n",
    "# 6. TRUST MODEL + METRICS\n",
    "# ============================================================\n",
    "def sigmoid(x): \n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "results = []\n",
    "per_edge_losses = {}\n",
    "\n",
    "for w in W_VALUES:\n",
    "    # Combine AUC and MI for composite reliability score\n",
    "    comp = {f: w * auc_scores[f] + (1 - w) * mi_norm[f] for f in X.columns}\n",
    "    \n",
    "    # Separate Weights\n",
    "    alpha_raw = {f: comp[f] for f in node_cols}\n",
    "    beta_raw  = {f: comp[f] for f in link_cols}\n",
    "    \n",
    "    # Normalize Weights (Fixed Indentation)\n",
    "    alpha = {k: v / (sum(alpha_raw.values()) + EPS) for k, v in alpha_raw.items()}\n",
    "    beta  = {k: v / (sum(beta_raw.values()) + EPS) for k, v in beta_raw.items()}\n",
    "\n",
    "    # Weighted sum calculation\n",
    "    z = (X[node_cols].values @ np.array(list(alpha.values())) +\n",
    "         X[link_cols].values @ np.array(list(beta.values())))\n",
    "\n",
    "    probs = sigmoid(z)\n",
    "    \n",
    "    # Binary Cross-Entropy Loss\n",
    "    loss = -(y * np.log(probs + EPS) + (1 - y) * np.log(1 - probs + EPS))\n",
    "    per_edge_losses[w] = loss\n",
    "\n",
    "    results.append([\n",
    "        w, \n",
    "        roc_auc_score(y, probs), \n",
    "        average_precision_score(y, probs), \n",
    "        loss.mean()\n",
    "    ])\n",
    "    print(f\"[OK] w={w} processed\")\n",
    "    \n",
    "\n",
    "# ============================================================\n",
    "# 7. SAVE RESULTS\n",
    "# ============================================================\n",
    "pd.DataFrame(results, columns=[\"w\", \"AUC\", \"AP\", \"LogLoss\"]).to_csv(f\"{OUTPUT_DIR}/ft_final_metrics.csv\", index=False)\n",
    "\n",
    "\n",
    "print(f\"\\n=== FILMTRUST PIPELINE COMPLETED ===\")\n",
    "print(f\"Results saved to {OUTPUT_DIR}/ft_final_metrics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c2e9b8b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] w=0.6 weights captured\n",
      "[OK] w=0.7 weights captured\n",
      "[OK] w=0.8 weights captured\n",
      "[OK] w=0.9 weights captured\n",
      "\n",
      "=== SUCCESS: Weights saved to outputs_filmtrust/ft_feature_weights.csv ===\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 6. TRUST MODEL + METRICS (FIXED WITH ALPHA/BETA TRACKING)\n",
    "# ============================================================\n",
    "def sigmoid(x): return 1 / (1 + np.exp(-x))\n",
    "\n",
    "metrics = []\n",
    "alpha_beta_rows = [] # Initialize the list to store weights\n",
    "\n",
    "for w in W_VALUES:\n",
    "    # Combine AUC and MI for composite reliability\n",
    "    comp = {f: w * auc_scores[f] + (1 - w) * mi_norm[f] for f in X.columns}\n",
    "    \n",
    "    # Separate and Normalize weights\n",
    "    alpha = {f: comp[f] for f in node_cols}\n",
    "    beta  = {f: comp[f] for f in link_cols}\n",
    "    \n",
    "    alpha = {k: v / (sum(alpha.values()) + EPS) for k, v in alpha.items()}\n",
    "    beta  = {k: v / (sum(beta.values()) + EPS) for k, v in beta.items()}\n",
    "\n",
    "    # Weighted sum calculation\n",
    "    z = (X[node_cols].values @ np.array(list(alpha.values())) +\n",
    "         X[link_cols].values @ np.array(list(beta.values())))\n",
    "\n",
    "    probs = sigmoid(z)\n",
    "    loss = -(y * np.log(probs + EPS) + (1 - y) * np.log(1 - probs + EPS))\n",
    "\n",
    "    # Save Performance Metrics\n",
    "    metrics.append([\n",
    "        w, roc_auc_score(y, probs), average_precision_score(y, probs), loss.mean()\n",
    "    ])\n",
    "\n",
    "    # Save Alpha and Beta Weights for this specific w\n",
    "    alpha_beta_rows.append({\n",
    "        \"w\": w,\n",
    "        **{f\"alpha_{k}\": v for k, v in alpha.items()},\n",
    "        **{f\"beta_{k}\": v for k, v in beta.items()}\n",
    "    })\n",
    "    print(f\"[OK] w={w} weights captured\")\n",
    "\n",
    "# ============================================================\n",
    "# 7. SAVE ALL RESULTS\n",
    "# ============================================================\n",
    "# Save performance (AUC, AP, Loss)\n",
    "pd.DataFrame(metrics, columns=[\"w\", \"AUC\", \"AP\", \"LogLoss\"]).to_csv(\n",
    "    f\"{OUTPUT_DIR}/ft_final_metrics.csv\", index=False\n",
    ")\n",
    "\n",
    "# Save Weights (The Alphas and Betas you want to see)\n",
    "pd.DataFrame(alpha_beta_rows).to_csv(\n",
    "    f\"{OUTPUT_DIR}/ft_feature_weights.csv\", index=False\n",
    ")\n",
    "\n",
    "print(f\"\\n=== SUCCESS: Weights saved to {OUTPUT_DIR}/ft_feature_weights.csv ===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1f0d9557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.8-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (52 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.61.1-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (114 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.9-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from matplotlib) (2.3.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from matplotlib) (12.0.0)\n",
      "Collecting pyparsing>=3 (from matplotlib)\n",
      "  Downloading pyparsing-3.3.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /home/codespace/.local/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Downloading matplotlib-3.10.8-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.3.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (362 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.61.1-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (5.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading kiwisolver-1.4.9-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyparsing-3.3.1-py3-none-any.whl (121 kB)\n",
      "Installing collected packages: pyparsing, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/6\u001b[0m [fonttools]\u001b[33m  WARNING: The scripts fonttools, pyftmerge, pyftsubset and ttx are installed in '/usr/local/python/3.12.1/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6/6\u001b[0m [matplotlib]6\u001b[0m [matplotlib]\n",
      "\u001b[1A\u001b[2KSuccessfully installed contourpy-1.3.3 cycler-0.12.1 fonttools-4.61.1 kiwisolver-1.4.9 matplotlib-3.10.8 pyparsing-3.3.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0e517cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Visualizations saved as PNG files in the current directory.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Load the saved metrics from the FilmTrust pipeline\n",
    "metrics_file = \"outputs_filmtrust/ft_final_metrics.csv\"\n",
    "\n",
    "try:\n",
    "    metrics_df = pd.read_csv(metrics_file)\n",
    "\n",
    "    # -------------------------\n",
    "    # AUC vs w\n",
    "    # -------------------------\n",
    "    plt.plot(metrics_df[\"w\"], metrics_df[\"AUC\"], marker=\"o\", color='blue', linestyle='-')\n",
    "    plt.xlabel(\"Weight (w)\")\n",
    "    plt.ylabel(\"AUC Score\")\n",
    "    plt.title(\"AUC vs Weight (FilmTrust)\")\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.savefig(\"ft_auc_vs_w.png\")\n",
    "    plt.clf()  # Clear for next plot\n",
    "\n",
    "    # -------------------------\n",
    "    # Average Precision vs w\n",
    "    # -------------------------\n",
    "    plt.plot(metrics_df[\"w\"], metrics_df[\"AP\"], marker=\"s\", color='green', linestyle='-')\n",
    "    plt.xlabel(\"Weight (w)\")\n",
    "    plt.ylabel(\"Average Precision\")\n",
    "    plt.title(\"Average Precision vs Weight (FilmTrust)\")\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.savefig(\"ft_ap_vs_w.png\")\n",
    "    plt.clf()\n",
    "\n",
    "    # -------------------------\n",
    "    # LogLoss vs w\n",
    "    # -------------------------\n",
    "    plt.plot(metrics_df[\"w\"], metrics_df[\"LogLoss\"], marker=\"d\", color='red', linestyle='-')\n",
    "    plt.xlabel(\"Weight (w)\")\n",
    "    plt.ylabel(\"LogLoss\")\n",
    "    plt.title(\"LogLoss vs Weight (Calibration Trade-off)\")\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.savefig(\"ft_logloss_vs_w.png\")\n",
    "    plt.clf()\n",
    "\n",
    "    print(\"[OK] Visualizations saved as PNG files in the current directory.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"[ERROR] Could not find {metrics_file}. Please run the pipeline first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8569ad0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
